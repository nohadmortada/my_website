---
title: "Group Project"
date: '2021-09-30'
description: Risk-Return of DJIA stocks
draft: no
image: Climate_Change.jpg
keywords: ''
slug: group_project
categories:
- ''
- ''
---

```{r setup, include=FALSE}
# leave this chunk alone
options(knitr.table.format = "html") 
knitr::opts_chunk$set(warning = FALSE, message = FALSE, 
  comment = NA, dpi = 300)
```

```{r load-libraries, echo=FALSE, include=FALSE}

library(tidyverse) # the usual stuff: dplyr, readr, and other goodies
library(lubridate) # to handle dates
library(GGally) # for correlation-scatter plot matrix
library(ggfortify) # to produce residual diagnostic plots
library(rsample) # to split dataframe in training- & testing sets
library(janitor) # clean_names()
library(broom) # use broom:augment() to get tidy table with regression output, residuals, etc
library(huxtable) # to get summary table of all models produced
library(kableExtra) # for formatting tables
library(moderndive) # for getting regression tables
library(skimr) # for skim
library(mosaic)
library(leaflet) # for interactive HTML maps
library(tidytext)
library(viridis)
library(vroom)

library(ggplot2)
library(dplyr)
library(GGally)
library(Amelia)
library(corrplot)

library(scales) # Visualization
library(caTools) # Prediction: Splitting Data
library(car) # Prediction: Checking Multicollinearity
library(ROCR) # Prediction: ROC Curve
library(e1071) # Prediction: SVM, Naive Bayes, Parameter Tuning
library(rpart) # Prediction: Decision Tree
library(rpart.plot) # Prediction: Decision Tree
library(randomForest) # Prediction: Random Forest
library(caret) # Prediction: k-Fold Cross Validation
library(gender)
```



```{r load_data, echo=FALSE, message=FALSE, warning=FALSE, cache=TRUE}

# use cache=TRUE so you dont donwload the data everytime you knit

listings <- vroom("http://data.insideairbnb.com/italy/lazio/rome/2021-09-12/data/listings.csv.gz") %>% 
       clean_names()

```

Even though there are many variables in the dataframe, here is a quick
description of some of the variables collected, and you can find a [data
dictionary
here](https://docs.google.com/spreadsheets/d/1iWCNJcSutYqpULSQHlNyGInUvHg2BoUGoNRIGa6Szc4/edit#gid=982310896)

-   `price` = cost per night

-   `property_type`: type of accommodation (House, Apartment, etc.)

-   `room_type`:

    -   Entire home/apt (guests have entire place to themselves)
    -   Private room (Guests have private room to sleep, all other rooms
        shared)
    -   Shared room (Guests sleep in room shared with others)

-   `number_of_reviews`: Total number of reviews for the listing

-   `review_scores_rating`: Average review score (0 - 100)

-   `longitude` , `latitude`: geographical coordinates to help us locate
    the listing

-   `neighbourhood*`: three variables on a few major neighbourhoods in
    each city

# Exploratory Data Analysis (EDA)

In the [R4DS Exploratory Data Analysis
chapter](http://r4ds.had.co.nz/exploratory-data-analysis.html){target="_blank"},
the authors state:

> "Your goal during EDA is to develop an understanding of your data. The
> easiest way to do this is to use questions as tools to guide your
> investigation... EDA is fundamentally a creative process. And like
> most creative processes, the key to asking quality questions is to
> generate a large quantity of questions."

Conduct a thorough EDA. Recall that an EDA involves three things:

-   Looking at the raw values.

    -   `dplyr::glimpse()`

-   Computing summary statistics of the variables of interest, or
    finding NAs

    -   `mosaic::favstats()`
    -   `skimr::skim()`

-   Creating informative visualizations.

    -   `ggplot2::ggplot()`

        -   `geom_histogram()` or `geom_density()` for numeric
            continuous variables
        -   `geom_bar()` or `geom_col()` for categorical variables

    -   `GGally::ggpairs()` for scaterrlot/correlation matrix

        -   Note that you can add transparency to points/density plots
            in the `aes` call, for example:
            `aes(colour = gender, alpha = 0.4)`

You may wish to have a level 1 header (`#`) for your EDA, then use level
2 sub-headers (`##`) to make sure you cover all three EDA bases. **At a
minimum** you should address these questions:

-   How many variables/columns? How many rows/observations?
-   Which variables are numbers?
-   Which are categorical or *factor* variables (numeric or character
    variables with variables that have a fixed and known set of possible
    values?
-   What are the correlations between variables? Does each scatterplot
    support a linear relationship between variables? Do any of the
    correlations appear to be conditional on the value of a categorical
    variable?
    
```{r}
dim(listings)
skim(listings)
str(listings)


#missing values
colSums(is.na(listings)|listings=="")
missmap(listings, main = "Missing values vs observed")


```

*There are 74 variables and 25097 observations.*

```{r}

# Price is a character and needs to be transformed into a numerical

listings <- listings %>% 
      mutate(price = parse_number(price),
             price_per_person=price/accommodates)

typeof(listings$price)

```

```{r}
#dropping variables that report the same information based on a qualitative analysis

variables_date<-c("id","host_since","last_scraped")

variables_log<-c("id","host_is_superhost","bathrooms","has_availability","host_identity_verified")

variables_num<-c("id","price","host_total_listings_count","latitude","longitude","accommodates","bedrooms", "minimum_nights","number_of_reviews","review_scores_rating","review_scores_accuracy","reviews_per_month","price_per_person")


variables_char<-c("id","room_type","neighbourhood_cleansed","host_name","amenities")


listings_num<- 
  listings %>%
  select_if( names(listings) %in% variables_num)

listings_date<- 
  listings %>%
  select_if( names(listings) %in% variables_date)


listings_char<- 
  listings %>%
  select_if( names(listings) %in% variables_char)

listings_log<- 
  listings %>%
  select_if( names(listings) %in% variables_log)

full<-cbind(listings_num,listings_date,listings_char,listings_log)

full<-inner_join(listings_num,listings_date,by="id")
full<-inner_join(full,listings_char,by="id")
full<-inner_join(full,listings_log,by="id")

dim(full)

missmap(full, main = "Missing values vs observed")
colSums(is.na(full)|full=="")
  
```


```{r}
# Data engineering

# 0 number of reviews determines no score rating, i.e. NA
filter(full, 
is.na(review_scores_rating)==TRUE|review_scores_rating==''& 
is.na(reviews_per_month)==TRUE|reviews_per_month=='' &
is.na(review_scores_accuracy)==TRUE|review_scores_accuracy=='')

filter(full, 
is.na(bathrooms)==TRUE|bathrooms=='')


# it seems that no superhost often implies a missing data for bathroom 
sum((is.na(full$bathrooms)) & (full$host_is_superhost==FALSE),na.rm=TRUE)/sum(is.na(full$bathrooms),na.rm=TRUE)


# we assume that if one is superhost the bathroom is present
idx<-full$host_is_superhost==TRUE | full$host_is_superhost==""
full$bathrooms[idx]<-TRUE


#drop 23 observations that are missing since 23 is small compared to 27lk
idy<-is.na(full$host_identity_verified) 
full<-full[!idy,]

#drop bathrooms since there are still too many missing data
full$bathrooms<-NULL

#Use alternative source of data for bathroom

#get the exact bathroom number from 'bathrooms_text'
library(stringr)
nmb<-NULL
listings <- listings %>% 
  mutate(a = strsplit(bathrooms_text,' '),
         bathroom = sapply(a,"[",1),
         bathroom_number = as.numeric(bathroom))
# extract the number of bathrooms 
for (i in 1:length(listings$bathrooms_text))
{
  nmb[i]=listings$a[[i]][1]
}
nmb<-as.numeric(nmb)
# create logic vector but everyone has a bathroom
bathrooms_log<-ifelse(nmb>0,TRUE,FALSE)
#compute bathrooms per person
bathrooms_per_person<-bathrooms_log/listings$accommodates

bath_data<-data.frame(id=listings$id,bathrooms_pp=bathrooms_per_person)
bath_data<-drop_na(bath_data)



idy<-full$price==0 
full<-full[!idy,]

filter(full, 
is.na(bedrooms)==TRUE|bedrooms=='')


# estimates missing bedrooms
ratio_people_bedrooms<-mean(full$accommodates/full$bedrooms,na.rm=TRUE)
boxplot(full$accommodates/full$bedrooms)
full$bedrooms[is.na(full$bedrooms)]=full$accommodates/ratio_people_bedrooms
boxplot(full$accommodates/full$bedrooms)

missmap(full, main = "Missing values vs observed")
colSums(is.na(full)|full=="")


```



```{r}

# create log price
full<- 
  full%>%
  mutate(log_price=log(price),
         log_price_per_person=log(price_per_person))

id<-full$number_of_reviews==0
full$reviews_per_month[id]=0

number_variables <- select_if(full, is.numeric)

number_var_relevant1<-number_variables[,c(1,2,5,6,8,9,12,14)]
number_var_relevant<-number_variables[,c(2,5,6,8,9,12,14)]

corrplot(cor(number_var_relevant))

#idx<-c(5,8,9,11,12,13,24,27)
#listings_plot<-number_variables[,idx]

corrplot(cor(number_var_relevant), method="number")

ggpairs(number_var_relevant)


# repeat for linear price

number_var_relevant_no_log<- number_var_relevant

number_var_relevant_no_log$log_price=number_variables$price
names(number_var_relevant_no_log)[7]="price"

corrplot(cor(number_var_relevant_no_log), method="number")
ggpairs(number_var_relevant_no_log)


# log price is better


```

## Propery types

Next, we look at the variable `property_type`. We can use the `count`
function to determine how many categories there are their frequency.
What are the top 4 most common property types? What proportion of the
total listings do they make up?
```{r}
listings_property <- listings%>%
  count(property_type)%>%
  arrange(desc(n))%>%
  mutate(pct=n/sum(n)*100)

listings_property %>%
  slice_max(order_by = n, n=4)%>%
  ggplot(aes(x = pct, y = fct_reorder(property_type,n))) +
  geom_col() +
  theme_bw()+
  labs(
    title = "",
    subtitle = "",
    x = "% of Total Listings",
    y = NULL
  )
```

Since the vast majority of the observations in the data are one of the
top four or five property types, we would like to create a simplified
version of `property_type` variable that has 5 categories: the top four
categories and `Other`. Fill in the code below to create
`prop_type_simplified`.

```{r}
    listings <- listings %>%
      mutate(prop_type_simplified = case_when(
        property_type %in% c("Entire rental unit","Private room in rental unit", "Private room in bed and breakfast","Entire condominium (condo)") ~ property_type, 
        TRUE ~ "Other"
      ))




      
```

Use the code below to check that `prop_type_simplified` was correctly
made.

```{r}
    listings %>%
      count(property_type, prop_type_simplified) %>%
      arrange(desc(n))   
    
```
```{r}


```


```{r}

head(listings_char)

# count amenities

# room type as a factor
unique(listings_char$room_type)
rooms<-factor((listings_char$room_type),levels=c("Shared room","Private room","Hotel room","Entire home/apt"),order=TRUE)
levels(rooms)
listings_char$room_type<-rooms

# neighbourhood factor
zone1<-c("II Parioli/Nomentano","I Centro Storico")
zone2<-c("XIII Aurelia","XII Monte Verde","III Monte Sacro","VIII Appia Antica","XIV Monte Mario")
zone3<-c("IV Tiburtina","V Prenestino/Centocelle","X Ostia/Acilia","VII San Giovanni/CinecittÃ ","IX Eur","VI Roma delle Torri","XI Arvalia/Portuense","V Prenestino/Centocelle","XV Cassia/Flaminia")


  
# classify zones of Rome based on distance from center and other factors
listing_char<-
listings_char %>% 
  mutate(zone = case_when(
    neighbourhood_cleansed %in% zone1 ~ "high",
    neighbourhood_cleansed %in% zone2 ~ "medium",
    neighbourhood_cleansed %in% zone3 ~ "low",
    TRUE ~ "other"
  )
)

zone_type<-factor((listings_char$zone),levels=c("other","low","medium","high"),order=TRUE)
levels(zone_type)
#listing_char$zone<-zone_type


#count amenities
n<-length(listing_char$amenities)
t<-NULL
for (i in 1:n)
{
t<-str_split(listing_char$amenities[i], ",", n = Inf, simplify = FALSE)
listing_char$number_amenities[i]<-lengths(t)
}

# add this to numeric dataset
number_var_relevant1<-inner_join(number_var_relevant1,listing_char[,c(1,7)],by="id")
number_var_relevant2<- inner_join(bath_data,number_var_relevant1,by="id")
number_var_relevant3<- subset( number_var_relevant2, select = -id )


corrplot(cor(number_var_relevant3), method="number")

# most significant char room type - zone -host name

```

```{r}

num_and_char<-inner_join(listing_char,number_var_relevant1)

ggplot(num_and_char,aes(zone,log_price)) +                                                  
  geom_boxplot(aes(fill=factor(zone)),alpha=0.5) +
  ggtitle("Title")

ggplot(num_and_char,aes(zone,number_of_reviews)) +                                                
  geom_boxplot(aes(fill=factor(zone)),alpha=0.5) +
  ggtitle("Title")

ggplot(num_and_char,aes(room_type,log_price)) +                                           
  geom_boxplot(aes(fill=factor(zone)),alpha=0.5) +
  ggtitle("Title")

ggplot(num_and_char,aes(room_type,number_of_reviews)) +                                           
  geom_boxplot(aes(fill=factor(zone)),alpha=0.5) +
  ggtitle("Title")

# add superhost 
num_and_char<-inner_join(full[,c(1,20,22)],num_and_char,by="id")

ggplot(num_and_char, aes(zone, fill=host_is_superhost)) + 
  geom_bar(aes(y = (..count..)/sum(..count..)), alpha=0.9, position="dodge") +
  scale_fill_brewer(palette = "Dark2", direction = -1) +
  scale_y_continuous(labels=percent, breaks=seq(0,0.6,0.05)) +
  ylab("Percentage") + 
  ggtitle("Percentage of superhost by location") +
  theme_bw() +
  theme(plot.title = element_text(hjust = 0.5))


ggplot(num_and_char, aes(room_type, fill=host_is_superhost)) + 
  geom_bar(aes(y = (..count..)/sum(..count..)), alpha=0.9, position="dodge") +
  scale_fill_brewer(palette = "Dark2", direction = -1) +
  scale_y_continuous(labels=percent, breaks=seq(0,0.6,0.05)) +
  ylab("Percentage") + 
  ggtitle("Title") +
  theme_bw() +
  theme(plot.title = element_text(hjust = 0.5))


num_and_char1<-
full %>% 
  mutate(has_reviews = case_when(
    number_of_reviews >0 ~ TRUE,
    TRUE ~ FALSE
  )
)

num_and_char$has_reviews<-num_and_char1$has_reviews

# number of reviews is more important for better type of rooms/accomodations
ggplot(num_and_char1, aes(room_type, fill=has_reviews)) + 
  geom_bar(aes(y = (..count..)/sum(..count..)), alpha=0.9, position="dodge") +
  scale_fill_brewer(palette = "Dark2", direction = -1) +
  scale_y_continuous(labels=percent, breaks=seq(0,0.6,0.05)) +
  ylab("Percentage") + 
  ggtitle("Title") +
  theme_bw() +
  theme(plot.title = element_text(hjust = 0.5))

# high region is associated with more reviews
ggplot(num_and_char, aes(zone, fill=has_reviews)) + 
  geom_bar(aes(y = (..count..)/sum(..count..)), alpha=0.9, position="dodge") +
  scale_fill_brewer(palette = "Dark2", direction = -1) +
  scale_y_continuous(labels=percent, breaks=seq(0,0.6,0.05)) +
  ylab("Percentage") + 
  ggtitle("Title") +
  theme_bw() +
  theme(plot.title = element_text(hjust = 0.5))

# number of amenities more important for low region indepenently from the number of reviews
num_and_char%>%
ggplot( aes(zone, number_amenities)) + 
  geom_violin(aes(fill=has_reviews), alpha=0.9) +
  facet_wrap(~has_reviews) + 
  scale_fill_brewer(palette = "Dark2", direction = -1) +
  ggtitle("Title") +
  theme_bw() +
  theme(plot.title = element_text(hjust = 0.5))


```



```{r, cache=TRUE}
#nams<-num_and_char$host_name
#define sex from host name



#t<-NULL
#sex<-NULL
#for (i in 1:length(nams))
#{
#t<-gender(nams[i])
#if (dim(t)[1]==0)
#{sex[i]="other"}
#else{
#sex[i]<-t$gender}
#}


#remove host name
num_and_char$host_name<-NULL

```







At this stage, you may also find you want to use `filter`, `mutate`,
`arrange`, `select`, or `count`. Let your questions lead you!

> In all cases, please think about the message your plot is conveying.
> Don't just say "This is my X-axis, this is my Y-axis", but rather
> what's the **so what** of the plot. Tell some sort of story and
> speculate about the differences in the patterns in no more than a
> paragraph.

## Data wrangling

Once you load the data, it's always a good idea to use `glimpse` to see
what kind of variables you have and what data type (`chr`, `num`,
`logical`, `date`, etc) they are.






Airbnb is most commonly used for travel purposes, i.e., as an
alternative to traditional hotels. We only want to include listings in
our regression analysis that are intended for travel purposes:

-   What are the most common values for the variable `minimum_nights`?
-   Is ther any value among the common values that stands out?
-   What is the likely intended purpose for Airbnb listings with this
    seemingly unusual value for `minimum_nights`?
    
    
**To be confirmed**

Filter the airbnb data so that it only includes observations with
`minimum_nights <= 4`

```{r}
listings_minnight <- listings%>%
  count(minimum_nights)%>%
  arrange(desc(n))%>%
  slice_max(order_by = n, n=10)

ggplot(listings_minnight,aes(x=minimum_nights,y=n))+
  geom_col()+
  theme_bw()+
  labs(
    title = "Most common 10 values of Minimum Nights",
    subtitle = "",
    x = "Minimum Nights of the Listing",
    y = "Count of listings"
  )

listings_fortravel<-listings %>%
  filter(minimum_nights <= 4)
```

```{r}

# collect all the data
full_new<-inner_join(listings_date,num_and_char,by="id")
dim(full_new)

listings_minnight <- full_new%>%
  count(minimum_nights)%>%
  arrange(desc(n))%>%
  slice_max(order_by = n, n=10)

ggplot(listings_minnight,aes(x=minimum_nights,y=n))+
  geom_col()+
  theme_bw()+
  labs(
    title = "Most common 10 values of Minimum Nights",
    subtitle = "",
    x = "Minimum Nights of the Listing",
    y = "Count of listings"
  )

listings_fortravel<-full_new %>%
  filter(minimum_nights <= 4)

dim(listings_fortravel)

```


# Mapping

Visualisations of feature distributions and their relations are key to
understanding a data set, and they can open up new lines of exploration.
While we do not have time to go into all the wonderful geospatial
visualisations one can do with R, you can use the following code to
start with a map of your city, and overlay all AirBnB coordinates to get
an overview of the spatial distribution of AirBnB rentals. For this
visualisation we use the `leaflet` package, which includes a variety of
tools for interactive maps, so you can easily zoom in-out, click on a
point to get the actual AirBnB listing for that specific point, etc.

The following code, having downloaded a dataframe `listings` with all
AirbnB listings in Milan, will plot on the map all AirBnBs where
`minimum_nights` is less than equal to four (4). You could learn more
about `leaflet`, by following [the relevant Datacamp course on mapping
with
leaflet](https://www.datacamp.com/courses/interactive-maps-with-leaflet-in-r)

```{r, out.width = '80%'}

leaflet(data = filter(listings, minimum_nights <= 4)) %>% 
  addProviderTiles("OpenStreetMap.Mapnik") %>% 
  addCircleMarkers(lng = ~longitude, 
                   lat = ~latitude, 
                   radius = 1, 
                   fillColor = "blue", 
                   fillOpacity = 0.4, 
                   popup = ~listing_url,
                   label = ~property_type)

listings_fortravel<-inner_join(listings_fortravel,number_variables[,c(1,3,4)],by="id")
temp_data<-inner_join(listings,listings_fortravel)

leaflet(temp_data) %>% 
  addProviderTiles("OpenStreetMap.Mapnik") %>% 
  addCircleMarkers(lng = ~longitude, 
                   lat = ~latitude, 
                   radius = 1, 
                   fillColor = "blue", 
                   fillOpacity = 0.4, 
                   popup = ~listing_url,
                   label = ~room_type)
```


# Regression Analysis

For the target variable $Y$, we will use the cost for two people to stay
at an Airbnb location for four (4) nights.

Create a new variable called `price_4_nights` that uses `price`, and
`accomodates` to calculate the total cost for two people to stay at the
Airbnb property for 4 nights. This is the variable $Y$ we want to
explain.

```{r}

 # listings_fortravel$price_4_nights<-listings_fortravel$price_per
listings_fortravel$price<-exp(listings_fortravel$log_price)

listings_fortravel$price_4_nights<-
  (listings_fortravel$price/listings_fortravel$accommodates)*8
listings_fortravel$log_price_4_nights<-log(listings_fortravel$price_4_nights)


#draw density plot of price and log price
p1<-ggplot(listings_fortravel, aes(x=price_4_nights))+
  geom_density()+
  theme_bw()
p1

p2<-ggplot(listings_fortravel, aes(x=log_price_4_nights))+
  geom_density()+
  theme_bw()
p2
```


Use histograms or density plots to examine the distributions of
`price_4_nights` and `log(price_4_nights)`. Which variable should you
use for the regression model? Why?

**We will choose log_price_4_nights as $Y$ because it is closer to normal distribution. The distribution of price_4_nights is right skewed.**

Fit a regression model called `model1` with the following explanatory
variables: `room_type`, `number_of_reviews`, and
`review_scores_rating`.

```{r}
   data4<-inner_join(listings[,c("id","review_scores_rating","prop_type_simplified","instant_bookable")],listings_fortravel[,],by="id")
  data4<-inner_join(bath_data,data4,by="id")

# set 0 review_scores_rating
id<-is.na(data4$review_scores_rating)

data4$review_scores_rating[id]=0




```
```{r}
# Splitting the Training set into the Training set and Validation set
set.seed(789)
split = sample.split(data4$id, SplitRatio = 0.8)
train = subset(data4, split == TRUE)
test = subset(data4, split == FALSE)

dim(train)
dim(test)


vars<-c("price","price_4_nights","log_price","amenities","neighbourhood_cleansed")
`%ni%` <- Negate(`%in%`)
temp<-subset(train,select = names(train) %ni% vars)

model = train(
  log_price_4_nights ~ .,
  data = temp,
  method = "knn",
  trControl = trainControl(method = "cv", number = 5),
  # preProcess = c("center", "scale"),
  tuneGrid = expand.grid(k = seq(1, 31, by = 2))
)



```
```{r}
print(model)
```




```{r}
get_best_result = function(caret_fit) {
  best = which(rownames(caret_fit$results) == rownames(caret_fit$bestTune))
  best_result = caret_fit$results[best, ]
  rownames(best_result) = NULL
  best_result
}
msummary(model)
print(model)
plot(model)
get_best_result(model)
```



```{r}


model2 <- lm(log_price_4_nights ~ prop_type_simplified + number_of_reviews + review_scores_rating, data=temp)
summary(model2)
model2 %>% broom::tidy()
print(model2)
autoplot(model2)


model1 <- lm(log_price_4_nights ~ room_type + number_of_reviews + review_scores_rating, data=temp)
msummary(model1)
model1 %>% broom::tidy()
print(model1)
autoplot(model1)



```

**The first model is better than the second one since one of the dummy variable of the simplified property type is not significant. This makes sense since one looks at the room more than the building when going to a Airbnb. The R square is very low.**

```{r}
# now act on the above indications and remove some variables
vars2<-c("latitude","longitude","accomodates","amenities","neighbourhood_cleansed","prop_type_simplified","id","price","price_4_nights","log_price","amenities","neighbourhood_cleansed","has_availability","review_scores_rating","host_since")

`%ni%` <- Negate(`%in%`)
temp<-subset(temp,select = names(temp) %ni% vars2)
```


```{r}
set.seed(123)
train.control = trainControl(method = "repeatedcv", number =100, repeats=3)
model_reg = train(log_price_4_nights ~ .,  data=temp, method="lm", trControl = train.control)
summary(model_reg)
print(model_reg)

```


```{r}

mdl<-glm(log_price_4_nights~.,data=temp)
mdl<-step(mdl)



```

**The first model is better than the second one since one of the dummy variable of the simplified property type is not significant. This makes sense since one looks at the room more than the building when going to a Airbnb. The R square is very low.**

```{r}
model3 <- lm(log_price_4_nights ~ ., data=temp)
summary(model3)
model3 %>% broom::tidy()
print(model3)


model4 <- lm(log_price_4_nights ~
               instant_bookable +room_type+
               zone+number_amenities+accommodates+bedrooms+
               number_of_reviews+minimum_nights+bathrooms_pp
             , data=temp)
summary(model4)
model4 %>% broom::tidy()
print(model4)
autoplot(model4)


model5 <- lm(log_price_4_nights ~
               room_type+zone+number_amenities+accommodates+bedrooms+
               number_of_reviews+minimum_nights
             , data=temp)
summary(model5)
model5 %>% broom::tidy()
print(model5)
anova(model5)
autoplot(model5)

```

```{r}

```



## Further variables/questions to explore on our own

Our dataset has many more variables, so here are some ideas on how you
can extend your analysis

1.  Are the number of `bathrooms`, `bedrooms`, `beds`, or size of the
    house (`accomodates`) significant predictors of `price_4_nights`? Or
    might these be co-linear variables?
2.  Do superhosts `(host_is_superhost`) command a pricing premium, after
    controlling for other variables?
```{r}
temp%>%
ggplot( aes(zone, log_price_4_nights)) + 
  geom_violin(aes(fill=host_is_superhost), alpha=0.9) +
  facet_wrap(~host_is_superhost) + 
  scale_fill_brewer(palette = "Dark2", direction = -1) +
  ggtitle("Title") +
  theme_bw() +
  theme(plot.title = element_text(hjust = 0.5))
```
  ** It doesn't seem the case**
    
3.  Some hosts allow you to immediately book their listing
    (`instant_bookable == TRUE`), while a non-trivial proportion don't.
    After controlling for other variables, is `instant_bookable` a
    significant predictor of `price_4_nights`?
```{r}

# 
ggplot(temp, aes(room_type, fill=instant_bookable)) + 
  geom_bar(aes(y = (..count..)/sum(..count..)), alpha=0.9, position="dodge") +
  scale_fill_brewer(palette = "Dark2", direction = -1) +
  scale_y_continuous(labels=percent, breaks=seq(0,0.6,0.05)) +
  ylab("Percentage") + 
  ggtitle("Title") +
  theme_bw() +
  theme(plot.title = element_text(hjust = 0.5))

ggplot(temp, aes(zone, fill=instant_bookable)) + 
  geom_bar(aes(y = (..count..)/sum(..count..)), alpha=0.9, position="dodge") +
  scale_fill_brewer(palette = "Dark2", direction = -1) +
  scale_y_continuous(labels=percent, breaks=seq(0,0.6,0.05)) +
  ylab("Percentage") + 
  ggtitle("Title") +
  theme_bw() +
  theme(plot.title = element_text(hjust = 0.5))

temp%>%
ggplot( aes(room_type, log_price_4_nights)) + 
  geom_violin(aes(fill=instant_bookable), alpha=0.9) +
  facet_wrap(~instant_bookable) + 
  scale_fill_brewer(palette = "Dark2", direction = -1) +
  ggtitle("Title") +
  theme_bw() +
  theme(plot.title = element_text(hjust = 0.5))

```
    
4.  For all cities, there are 3 variables that relate to neighbourhoods:
    `neighbourhood`, `neighbourhood_cleansed`, and
    `neighbourhood_group_cleansed`. There are typically more than 20
    neighbourhoods in each city, and it wouldn't make sense to include
    them all in your model. Use your city knowledge, or ask someone with
    city knowledge, and see whether you can group neighbourhoods
    together so the majority of listings falls in fewer (5-6 max)
    geographical areas. You would thus need to create a new categorical
    variabale `neighbourhood_simplified` and determine whether location
    is a predictor of `price_4_nights`
    
```{r}
model6 <- lm(log_price_4_nights ~
               zone+bathrooms_pp+room_type
             , data=temp)
summary(model5)
model5 %>% broom::tidy()
print(model5)


```
    
```{r,warning=FALSE}
# Summary of all models



# model_reg
print(model_reg)
#vif(model_reg)
```


```{r,warning=FALSE}
#model1
summ(model1)
vif(model1)

# model2
summ(model2)
vif(model2)
```



```{r,warning=FALSE}
#model
print(model)
#vif(model)

```


```{r,warning=FALSE}
#model3
summ(model3)
vif(model3)

```

```{r,warning=FALSE}
#model4
summ(model4)
vif(model4)
```

```{r,warning=FALSE}
#model5
summ(model5)
(vif(model5))
```

```{r,warning=FALSE}

# model 3
chisqmatrix <- function(x) {
  names = colnames(x);  num = length(names)
  m = matrix(nrow=num,ncol=num,dimnames=list(names,names))
  for (i in 1:(num-1)) {
    for (j in (i+1):num) {
      m[i,j] = chisq.test(x[,i],x[,j],)$p.value
    }
  }
  return (m)
}
temp$zone<-as.factor(temp$zone)
train_cat = select_if(temp, is.factor)
head(train_cat)
train_cat = train_cat[,names(train_cat)!="log_price_4_nights"]
mat = chisqmatrix(train_cat)
mat

```


```{r}

```
    
    
    
5.  What is the effect of `avalability_30` or `reviews_per_month` on
    `price_4_nights`, after we control for other variables?
    
```{r}

```
    

## Diagnostics, collinearity, summary tables

As you keep building your models, it makes sense to:

1.  Check the residuals, using `autoplot(model_x)`

2.  As you start building models with more explanatory variables, make
    sure you use \`car::vif(model_x)\`\` to calculate the **Variance
    Inflation Factor (VIF)** for your predictors and determine whether
    you have colinear variables. A general guideline is that a VIF
    larger than 5 or 10 is large, and your model may suffer from
    collinearity. Remove the variable in question and run your model
    again without it.

3.  Create a summary table, using `huxtable`
    (<https://mfa2022.netlify.app/example/modelling_side_by_side_tables/>)
    that shows which models you worked on, which predictors are
    significant, the adjusted $R^2$, and the Residual Standard Error.

4.  Finally, you must use the best model you came up with for
    prediction. Suppose you are planning to visit the city you have been
    assigned to over reading week, and you want to stay in an Airbnb.
    Find Airbnb's in your destination city that are apartments with a
    private room, have at least 10 reviews, and an average rating of at
    least 90. Use your best model to predict the total cost to stay at
    this Airbnb for 4 nights. Include the appropriate 95% interval with
    your prediction. Report the point prediction and interval in terms
    of `price_4_nights`.
    
```{r}

```
  

-   if you used a log(price_4\_nights) model, make sure you anti-log to
    convert the value in \$. You can read more about [hot to interpret a
    regression model when some variables are log transformed
    here](https://stats.idre.ucla.edu/other/mult-pkg/faq/general/faqhow-do-i-interpret-a-regression-model-when-some-variables-are-log-transformed/)

# Deliverables

-   By midnight on Monday 17 Oct 2022, you must upload on Canvas a short
    presentation (max 4-5 slides) with your findings, as some groups
    will be asked to present in class. You should present your
    Exploratory Data Analysis, as well as your best model. In addition,
    you must upload on Canvas your final report, written using R
    Markdown to introduce, frame, and describe your story and findings.
    You should include the following in the memo:

1.  Executive Summary: Based on your best model, indicate the factors
    that influence `price_4_nights`. This should be written for an
    intelligent but non-technical audience. All other sections can
    include technical writing.
2.  Data Exploration and Feature Selection: Present key elements of the
    data, including tables and graphs that help the reader understand
    the important variables in the dataset. Describe how the data was
    cleaned and prepared, including feature selection, transformations,
    interactions, and other approaches you considered.
3.  Model Selection and Validation: Describe the model fitting and
    validation process used. State the model you selected and why they
    are preferable to other choices.
4.  Findings and Recommendations: Interpret the results of the selected
    model and discuss additional steps that might improve the analysis

Remember to follow R Markdown etiquette rules and style; don't have the
Rmd output extraneous messages or warnings, include summary tables in
nice tables (use `kableExtra`), and remove any placeholder texts from
past Rmd templates; in other words, (i.e. I don't want to see stuff I
wrote in your final report.)

# Rubric

Your work will be assessed on a rubric which you can find here

```{r rubric, echo=FALSE, out.width="100%"}
knitr::include_graphics(here::here("images", "rubric.png"), error = FALSE)
```

# Acknowledgements

-   The data for this project is from
    [insideairbnb.com](insideairbnb.com)
